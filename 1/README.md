# 1
## Answers
### 1. 1. The data extraction depends on format of raw data (most likely it will be a binary data from stream). For the data to be conventional for our system I would parse the data into JSON (With game identifiers, time intervals, etc.). The size of JSON should not be a big problem as I expect data to not be cumulative. The main problem I think may be with parsing data from many concurrent games as it may cause some overloads inside the system. Probably there should be implemented some sort of scaling for this gateway. After the parse of JSON the data also will be sent to:
###  - Lightweight API where it is separated into the most valuable data which will be available to end users through Pub/Sub mechanism. I moved the separation of data into separate gateway/service to not overload parsing gateway even more.  ###  - Statistics service where based on identifiers and time intervals data will be saved into DB in form of statistics and will be available to users through RESTful api. (Both close to real time and after game). This statistics will be updated every 1 minute (to not overload the service), even though the data updates may come faster from parsing gateway (most likely new JSON data will be stored in queue).